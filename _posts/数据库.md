---
title: 数据库
categories:
  - 数据库
tags:
  - 优化
  - 读写分离
  - 主备方案
date: 2018-07-07 20:48:56
---
 数据库相关知识
 <!-- more -->



# 分库分表
>参考地址:http://www.infoq.com/cn/articles/key-steps-and-likely-problems-of-split-table

## 垂直分表
就是大表拆成小表,一张表字段过多可以考虑拆分成几张表,将不经常使用或者长度较大的字段拆分出去放到“扩展表”中
1. 优点
在字段很多的情况下，拆分开确实更便于开发和维护。某种意义上也能避免“跨页”的问题
2. 缺点
拆分字段的操作建议在数据库设计阶段就做好。如果是在发展过程中拆分，则需要改写以前的查询语句，会额外带来一定的成本和风险，建议谨慎。

## 垂直分库
基本的思路就是按照业务模块来划分出不同的数据库，而不是像早期一样将所有的数据表都放到同一个数据库中。
1. 优点
系统层面的“服务化”拆分操作，能够解决业务系统层面的耦合和性能瓶颈，有利于系统的扩展维护。而数据库层面的拆分，道理也是相通的。与服务的“治理”和“降级”机制类似，我们也能对不同业务类型的数据进行“分级”管理、维护、监控、扩展等。
数据库的连接资源比较宝贵且单机处理能力也有限，在高并发场景下，垂直分库一定程度上能够突破IO、连接数及单机硬件资源的瓶颈，是大型分布式系统中优化数据库架构的重要手段。
2. 缺点
跨库join，分布式事务等
3. 难点解决思路
  1. 垮库join
    * 字段冗余:
    可以不用去查询另一张表,空间换时间
    * 简单字段,系统层组装
    在代码中调用不同模块的服务获取数据后进行组装
    * 复杂字段
    尽量将数据通过条件过滤之后再返回进行组装
  2. 跨库事务（分布式事务）的问题 

## 水平分表
就是将表中不同的数据行按照一定规律分布到不同的数据库表中（这些表保存在同一个数据库中），这样来降低单表数据量，优化查询性能。最常见的方式就是通过主键或者时间等字段进行Hash和取模后拆分。
1. 优点
水平分表，能够降低单表的数据量，一定程度上可以缓解查询性能瓶颈。
2. 缺点
但本质上这些表还保存在同一个库中，所以库级别还是会有IO瓶颈。所以，一般不建议采用这种做法。

## 水平分库分表
水平分库分表与上面讲到的水平分表的思想相同，唯一不同的就是将这些拆分出来的表保存在不同的数据库中。
>参考地址:http://www.infoq.com/cn/articles/key-steps-and-likely-problems-of-horizontal-split-table


# 读写分离
>参考地址:https://blog.csdn.net/justdb/article/details/17331569



## 概念
1. what
读写分离，基本的原理是让主数据库处理事务性增、改、删操作（INSERT、UPDATE、DELETE），而从数据库处理SELECT查询操作。数据库复制被用来把事务性操作导致的变更同步到集群中的从数据库。
2. why
所以读写分离，解决的是，数据库的写入，影响了查询的效率。
3. when
数据库不一定要读写分离，**如果程序使用数据库较多时，而更新少，查询多的情况下会考虑使用，利用数据库 主从同步 。可以减少数据库压力，提高性能。**当然，数据库也有其它优化方案。memcache 或是 表折分，或是搜索引擎。都是解决方法。
{% asset_img 读写分离.png 读写分离%}

## 提高性能的原因
1. 物理服务器增加，负荷增加
2. 主从只负责各自的写和读，极大程度的缓解X锁和S锁争用
3. 从库可配置myisam引擎，提升查询性能以及节约系统开销
4. 从库同步主库的数据和主库直接写还是有区别的，通过主库发送来的binlog恢复数据，但是，最重要区别在于主库向从库发送binlog是异步的，从库恢复数据也是异步的
5. 读写分离适用与读远大于写的场景，如果只有一台服务器，当select很多时，update和delete会被这些select访问中的数据堵塞，等待select结束，并发性能不高。 对于写和读比例相近的应用，应该部署双主相互复制
6. 可以在从库启动是增加一些参数来提高其读的性能，例如--skip-innodb、--skip-bdb、--low-priority-updates以及--delay-key-write=ALL。当然这些设置也是需要根据具体业务需求来定得，不一定能用上
7. 分摊读取。假如我们有1主3从，不考虑上述1中提到的从库单方面设置，假设现在1分钟内有10条写入，150条读取。那么，1主3从相当于共计40条写入，而读取总数没变，因此平均下来每台服务器承担了10条写入和50条读取（主库不承担读取操作）。因此，虽然写入没变，但是读取大大分摊了，提高了系统性能。另外，当读取被分摊后，又间接提高了写入的性能。所以，总体性能提高了，说白了就是拿机器和带宽换性能。MySQL官方文档中有相关演算公式：官方文档 见6.9FAQ之“MySQL复制能够何时和多大程度提高系统性能”
8. MySQL复制另外一大功能是增加冗余，提高可用性，当一台数据库服务器宕机后能通过调整另外一台从库来以最快的速度恢复服务，因此不能光看性能，也就是说1主1从也是可以的。

# Mysql主从同步方案(实现读写分离)
>参考地址: https://www.jianshu.com/p/ab704b437ebd

## 实现
基于binlog实现
>参考地址:https://jaminzhang.github.io/mysql/MySQL-Master-Slave-Replication-Principle/

## 流程
1. master要开启binlog功能
2. slave上执行`start slave`,然后slave的IO线程会向master请求其binlog中指定位置之后的内容
3. master上的IO线程收到请求之后会将binlog中指定位置之后的日志信息返回,同时包含新的binlog文件名和下一个指定的更新位置
4. slave的IO线程接受到日志数据之后,将数据添加到本地的中继日志(relay log)的末端,并记录新的binlog文件名和下一个更新位置,
5. 当slave的SQL线程检测到中继日志中有新内容的时候,将日志内容解析成SQL执行
{% asset_img mysql主从复制.jpeg %}

## 主从切换的注意点
master故障是binlog没有及时传给slave,各个slave数据不一致
1. 确保binlog全部传到slave
  1. 半同步,事务提交之后只有binlog传到slave之后才算结束,影响性能
  2. 通过os层文件系统将binlog保存到备用机
2. 如果允许数据丢失
在salve中选择一个binlog最新的变成master,原master恢复后,将数据回退

# 慢查询优化:
## 分析sql方法
参考地址:https://blog.csdn.net/u012990533/article/details/45643509
`explain select * from table where table.id = 1 `
运行上面的sql语句后你会看到，下面的表头信息：
`table | type | possible_keys | key | key_len | ref | rows | Extra`
1. table 
显示这一行的数据是关于哪张表的
2. type 
这是重要的列，显示连接使用了何种类型。从最好到最差的连接类型为const、eq_reg、ref、range、indexhe和ALL
说明：不同连接类型的解释（按照效率高低的顺序排序）
    * system：表只有一行：system表。这是const连接类型的特殊情况。
    * const ：表中的一个记录的最大值能够匹配这个查询（索引可以是主键或惟一索引）。因为只有一行，这个值实际就是常数，因为MYSQL先读这个值然后把它当做常数来对待。
    * eq_ref：在连接中，MYSQL在查询时，从前面的表中，对每一个记录的联合都从表中读取一个记录，它在查询使用了索引为主键或惟一键的全部时使用。
    * ref：这个连接类型只有在查询使用了不是惟一或主键的键或者是这些类型的部分（比如，利用最左边前缀）时发生。对于之前的表的每一个行联合，全部记录都将从表中读出。这个类型严重依赖于根据索引匹配的记录多少—越少越好。
    * range：这个连接类型使用索引返回一个范围中的行，比如使用>或<查找东西时发生的情况。
    * index：这个连接类型对前面的表中的每一个记录联合进行完全扫描（比ALL更好，因为索引一般小于表数据）。
    * ALL：这个连接类型对于前面的每一个记录联合进行完全扫描，这一般比较糟糕，应该尽量避免。
3. possible_keys 
显示可能应用在这张表中的索引。如果为空，没有可能的索引。可以为相关的域从WHERE语句中选择一个合适的语句
4. key 
实际使用的索引。如果为NULL，则没有使用索引。很少的情况下，MYSQL会选择优化不足的索引。这种情况下，可以在SELECT语句中使用USE INDEX（indexname）来强制使用一个索引或者用IGNORE INDEX（indexname）来强制MYSQL忽略索引
5. key_len 
使用的索引的长度。在不损失精确性的情况下，长度越短越好
6. ref 
显示索引的哪一列被使用了，如果可能的话，是一个常数
7. rows 
MYSQL认为必须检查的用来返回请求数据的行数
8. Extra 
关于MYSQL如何解析查询的额外信息。将在表4.3中讨论，但这里可以看到的坏的例子是Using temporary和Using filesort，意思MYSQL根本不能使用索引，结果是检索会很慢
说明：extra列返回的描述的意义
    * Distinct ：一旦mysql找到了与行相联合匹配的行，就不再搜索了。
    * Not exists ：mysql优化了LEFT JOIN，一旦它找到了匹配LEFT JOIN标准的行，就不再搜索了。
    * Range checked for each Record（index map:#） ：没有找到理想的索引，因此对从前面表中来的每一个行组合，mysql检查使用哪个索引，并用它来从表中返回行。这是使用索引的最慢的连接之一。
    * Using filesort ：看到这个的时候，查询就需要优化了。mysql需要进行额外的步骤来发现如何对返回的行排序。它根据连接类型以及存储排序键值和匹配条件的全部行的行指针来排序全部行。
    * Using index ：列数据是从仅仅使用了索引中的信息而没有读取实际的行动的表返回的，这发生在对表的全部的请求列都是同一个索引的部分的时候。
    * Using temporary ：看到这个的时候，查询需要优化了。这里，mysql需要创建一个临时表来存储结果，这通常发生在对不同的列集进行ORDER BY上，而不是GROUP BY上。
    * Where used ：使用了WHERE从句来限制哪些行将与下一张表匹配或者是返回给用户。如果不想返回表中的全部行，并且连接类型ALL或index，这就会发生，或者是查询有问题。

## 优化方法
参考地址:https://tech.meituan.com/mysql-index.html
1. 先运行看看是否真的很慢，注意设置SQL_NO_CACHE
1. where条件单表查，锁定最小返回记录表。这句话的意思是把查询语句的where都应用到表中返回的记录数最小的表开始查起，单表每个字段分别查询，看哪个字段的区分度最高
2. explain查看执行计划，是否与1预期一致（从锁定记录较少的表开始查询）比如`explain select * from test1 where id=1;`
3. order by limit 形式的sql语句让排序的表优先查
4. 了解业务方使用场景
5. 加索引时参照建索引的几大原则
6. 观察结果，不符合预期继续从0分析

# 完整的对象访问名称
## Oracle
参考地址:https://blog.csdn.net/KimSoft/article/details/4627520


# 数据库事务

>参考地址:http://www.hollischuang.com/archives/898
## 命令行
1. 查看隔离级别
`SELECT @@tx_isolation;`
2. 查看存储引擎
`show variables like '%storage_engine%';`

## 锁
1. 行级锁
行级锁是Mysql中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。
开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。
  1. 排它锁(写锁)
  `SELECT ... FOR UPDATE;`
  排他锁又称写锁，如果事务T对数据A加上排他锁后，则其他事务不能再对A加任任何类型的封锁。获准排他锁的事务既能读数据，又能修改数据。
  2. 共享锁(读锁)
  `SELECT ... LOCK IN SHARE MODE;`
  如果事务T对数据A加上共享锁后，则其他事务只能对A再加共享锁，不能加排他锁。获准共享锁的事务只能读数据，不能修改数据。

2. 表级锁
表级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使用的MYISAM与INNODB都支持表级锁定。
开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度最低。
  1. 表共享读锁(共享锁)
  2. 表独占写锁(排他锁)
  3. 意向共享锁(IS)
  4. 意向互斥锁(IX)
>有的人可能会对意向锁(intention lock)的目的并不是完全的理解，我们在这里可以举一个例子：如果没有意向锁，当已经有人使用行锁对表中的某一行进行修改时，如果另外一个请求要对全表进行修改，那么就需要对所有的行是否被锁定进行扫描，在这种情况下，效率是非常低的；不过，在引入意向锁之后，当有人使用行锁对表中的某一行进行修改之前，会先为表添加意向互斥锁（IX），再为行记录添加互斥锁（X），在这时如果有人尝试对全表进行修改就不需要判断表中的每一行数据是否被加锁了，只需要通过等待意向互斥锁被释放就可以了。
3. 页级锁
页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。一次锁定相邻的一组记录。BDB支持页级锁

## 锁算法
1. 记录锁
记录锁（Record Lock）是加到索引记录上的锁,如果我们使用 id 或者 last_name 作为 SQL 中 WHERE 语句的过滤条件，那么 InnoDB 就可以通过索引建立的 B+ 树找到行记录并添加索引，但是如果使用 first_name 作为过滤条件时，由于 InnoDB 不知道待修改的记录具体存放的位置，也无法对将要修改哪条记录提前做出判断就会锁定整个表。
2. 间隙锁
间隙锁是对索引记录中的一段连续区域的锁；当使用类似 `SELECT * FROM users WHERE id BETWEEN 10 AND 20 FOR UPDATE;` 的 SQL 语句时，就会阻止其他事务向表中插入 `id = 15 `的记录，因为整个范围都被间隙锁锁定了。
3. next-key锁(解决幻读)
当我们更新一条记录，比如 `SELECT * FROM users WHERE age = 30 FOR UPDATE;`，InnoDB 不仅会在范围 (21, 30] 上加 Next-Key 锁，还会在这条记录后面的范围 (30, 40] 加间隙锁，所以插入 (21, 40] 范围内的记录都会被锁定。

## 事务概念
一个数据库事务通常包含对数据库的读或写的一个操作序列,它存在的目的如下:
1. 为数据库操作提供一个从失败状态恢复到正常状态的方法,同时提供了数据库即使在异常状态也能保持一致性的方法
2. 当多个应用程序并发访问数据库时,提供隔离这些操作的方法,避免操作之间相互干扰

## 事务特性(ACID)
数据库事务:银行转账的例子
1. 原子性(atomicity)
事务中对数据库的一系列操作要么全部被执行,要么都不执行
2. 一致性(consistent)
从一个一致性状态变到另一个一致性状态,满足数据库的完整性约束
3. 隔离性(isolation)
多个事务并发执行的时候,一个事务不会影响到另一个事务
4. 持久性(Durability)
事务一旦提交成功,对数据库的修改将永久保存在数据库中

## 事务的隔离级别
参考地址:http://www.hollischuang.com/archives/943
1. 未提交读(read Uncommited)
  * 概念
  一个事务可以读取另一个事务未提交的数据
  * 实现
  事务读取数据的时候不加锁
  事务修改数据的时候加行级共享锁
  * 可能现象
  出现脏读
2. 提交读(read committed) 
  * 概念
  在一个事务修改数据过程中，如果事务还没提交，其他事务不能读该数据。解决脏读
  * 实现
  事务对当前被读取的数据加 行级共享锁（当读到时才加锁），一旦读完该行，立即释放该行级共享锁；
  事务在更新某数据的瞬间（就是发生更新的瞬间），必须先对其加 行级排他锁，直到事务结束才释放。
  * 可能现象
  不可重复读:对于同一数据项,前面读取的数据和后来读取的数据可能不一样
  可能出现不可重复读和幻读
3. 可重复读(repeated read) 
  * 概念
  可重复读,只有在事务一提交之后，事务二才能更改该行数据。所以，只要在事务一从开始到结束的这段时间内，无论他读取该行数据多少次，结果都是一样的。解决不可重复读
  * 实现
  事务在读取某数据的瞬间（就是开始读取的瞬间），必须先对其加 行级共享锁，直到事务结束才释放；
  事务在更新某数据的瞬间（就是发生更新的瞬间），必须先对其加 行级排他锁，直到事务结束才释放。
  innodb中使用快照技术,即晚于当前事务的其他的事务的更新对本事务不可见
  * 可能现象
  数据库进行读事务的时候就会禁止其他的写事务,进行写事务的时候就会禁止其他任何事务写操作
  可能出现幻读,因为其他事务虽然不能修改该行数据,但是可以新增数据行,
4. 可序列化(serializable) 
  * 概念
  可序列化:最高级别,事务串行,解决幻读
  * 实现
  事务在读取数据时，必须先对其加 表级共享锁 ，直到事务结束才释放；
  事务在更新数据时，必须先对其加 表级排他锁 ，直到事务结束才释放。
  * 可能现象
  虽然可序列化解决了脏读、不可重复读、幻读等读现象。但是序列化事务会产生以下效果：
    1. 无法读取其它事务已修改但未提交的记录。
    2. 在当前事务完成之前，其它事务不能修改目前事务已读取的记录。
    3. 在当前事务完成之前，其它事务所插入的新记录，其索引键值不能在当前事务的任何语句所读取的索引键范围中。


## 由于低级别隔离性产生的问题:
1. 脏读:session1查询test为空,此时session2插入数据不提交,然后session再次查询test就有数据了
{% asset_img 脏读.jpg 脏读 %}
提交读解决脏读的方法在于,当session2插入数据的时候加了排他行锁,直到session2提交才能被访问到
2. 不可重复读:session1查询id=3的地方v=2,此时session2把v改成3并且提交,session1再次查询id=2的地方v变成了3,同一事务前后访问不一致,重点在同一条记录
{% asset_img 不可重复读.jpg 不可重复读 %}
可重复读解决不可重复读的方法在于,当session1读取数据的时候加了共享行锁,知道session1结束才释放,所以session2无法修改数据
3. 幻读:重点在插入了新数据,session1查询返回结果为空表,此时session2插入新数据1并提交,(图中有误,第二次查询应去掉)然后事务1也插入数据1,此时报错,刚刚明明是空表,现在却提示数据冲突.
{% asset_img 幻读.jpg 幻读 %}
出现幻读的原因是可重复读虽然加了行锁,但是无法阻止数据的插入,解决的办法就是加表锁,还有乐观锁机制?


## mysql常用存储引擎
1. MyISAM和MEMORY采用表级锁(table-level locking)
  1. 在myisam中是不会出现死锁的,因为一次性获取所有需要的锁要么全部满足,要么全部等待
2. BDB采用页面锁(page-level locking)或表级锁，默认为页面锁
3. InnoDB支持行级锁(row-level locking)和表级锁,默认为行级锁
innodb中的行锁实现原理是在索引中的索引项上加锁,所以只有通过索引条件检索数据InnoDB才会使用行锁,否则使用的是表锁
  实际应用:
  1. 因为MySQL行锁是针对索引,而不是记录,所以使用相同的索引键,即使是访问不同的行也会产生锁冲突
  2. 如果一张表使用多个索引,那么可以根据不同的索引键访问不同的行
在MySQL中，行级锁并不是直接锁记录，而是锁索引。索引分为主键索引和非主键索引两种，如果一条sql语句操作了主键索引，MySQL就会锁定这条主键索引；如果一条语句操作了非主键索引，MySQL会先锁定该非主键索引，再锁定相关的主键索引。 在UPDATE、DELETE操作时，MySQL不仅锁定WHERE条件扫描过的所有索引记录，而且会锁定相邻的键值，即所谓的next-key locking。
当两个事务同时执行，一个锁住了主键索引，在等待其他相关索引。另一个锁定了非主键索引，在等待主键索引。这样就会发生死锁。
发生死锁后，InnoDB一般都可以检测到，并使一个事务释放锁回退，另一个获取锁完成事务。
参考地址:https://draveness.me/mysql-innodb

### InnoDb和MyISAM的区别
> 参考地址:https://juejin.im/post/5b02b105f265da0b7868d230

|InnoDb|MyISAM|
|------|--------|
|I支持行级锁和表级锁;行级锁基于索引实现,只对where的主键有效|M只支持表级锁|
|提供事务支持|M强调性能,不支持事务|
|支持外键|不支持外键|
|适合大量的insert和update|适合大量的select|
|适合写多,字段更新频繁,高并发,安全可用性高|读多写少,并发小,表数据量小,硬件资源有限|
|数据文件,binlog,mysqldump|数据以文件形式存储,数据转移方便|

## 产生死锁的可能:
{% asset_img 死锁的发生.jpg 死锁的发生 %}
1. 事务1获取数据a的锁,想要访问数据b,但是此时数据b被事务2锁定,而事务2希望访问数据a,陷入相互等待的局面.
解决的方式就是从根源上避免这种情况的出现,就是修改程序逻辑,避免出现环,可以一开始就将所有要用到的资源锁定
还有就是采用抢占和回滚机制,根据时间戳来判断事务应该回滚还是等待

## 避免死锁的方式
1. 如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会。
2. 在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率；
3. 对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过表级锁定来减少死锁产生的概率；

## 并发控制机制
参考地址:http://www.hollischuang.com/archives/934
1. 悲观锁(是真正的锁)
就是之前的共享锁和互斥锁(排它锁),就是不管如何,想要修改数据之前先加锁,可能会产生死锁
2. 乐观锁(其实是一种并发控制思想,基于时间戳或者版本号)
这种思想假设数据操作的时候一般不会产生冲突,只有在最后要写回数据的时候检测数据是否发生了变化,发生冲突的话进行重试或者返回错误信息让用户决定怎么处理,否则就可以正常写回
在整个执行过程中实际上并没有加任何锁,在要求响应速度和高并发的场景下适合,不会产生死锁,但是在高冲突频率重试成本的情况下还是建议使用悲观锁
  1. 版本控制:就是为数据的每一个写操作创建版本,在进行读操作的时候就会在有限多的版本中选择最合适的返回
  通常是在数据表中增加一列version,然后写回数据的时候比对version
  2. 基于时间戳

# 数据库索引
## 优缺点
1. 优点
    1. 大大加快数据的检索速度，这也是创建索引的最主要的原因；
    2. 可以创建唯一性索引，保证数据库表中每一行数据的唯一性；
    3. 可以将表的外键制作为索引，加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义；
    4. 将随机I/O变为顺序I/O，帮助服务器避免排序和临时表，在使用分组和排序子句进行数据检索时，可以显著减少查询中分组和排序的时间；
    5. 通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。
2. 缺点
    1. 创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加；
    2. 索引需要占物理空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间；
    3. 当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度。
3. 关于mysql索引:
    1. BTree 索引是大多数 MySQL 存储引擎的默认索引类型
    2. 在 MySQL 中只有 Memory 引擎显式支持哈希索引
    3. 哈希索引只包含 哈希值和行指针，而不存储字段值
    4. 索引将随机 I/O变为顺序 I/O

## innodb
### 行锁原理
### 与myisam的区别
见数据库事务
### innodb中的索引知识小结
>参考地址:http://www.hollischuang.com/archives/1712

## 不同查询条件下的命中情况

## 聚集索引
## 加速原理
### 磁盘读写原理和效率
>参考地址:https://blog.csdn.net/v_july_v/article/details/6530142

1. 读写数据时间的组成
    * 查找时间:就是磁头移动到需要的柱面上(一个圈就叫柱面),定位到指定磁道,时间代价最大,最大可达0.1s
    * 等待时间:盘片开始旋转,将指定的磁道段移动到磁头下,因为硬盘转速有7200转/分,所以转一圈的时间就0.0083s,很快
    * 传输时间:数据通过系统总线到内存的时间,传输一个byte0.02微秒(`2*10^-8`s)
2. 提速手段
    硬盘读取数据的速度是以块(block)为基本单位的,而磁盘IO的时间代价主要花费在查找时间,因此一方面要将相关数据放在相近的区域(同一盘块,同一磁道,或者至少放在同一柱面或者相邻柱面),减少读/写数据时来回移动磁头的次数

### B树(B-树)
也是一种多叉平衡查找树,一个节点内有x个关键字,那么这个节点就有x+1个子节点
{% asset_img b树的结构.jpg b树的结构%}
如上图树查找字母R的路径
{% asset_img b树文件查找过程.jpg b树文件查找过程%}
根节点中的17代表一个磁盘文件的文件名,**红色方块代表17文件在硬盘中的存储位置(这就是和B+树的主要区别)**,P1指向17的左子树.



### B+树的介绍
>参考地址:http://blog.csdn.net/guoziqing506/article/details/64122287

与b树相比较
1. b+树的磁盘读写代价更低,因为b+树的内部节点**并没有指向关键字的指针的具体信息**,所以盘快内可以容纳更多的关键字,盘块读进内存后查找的范围更大,从而降低树的高度
2. 查询效率更加稳定,因为内部节点并不是指向最终文件内容的节点,而是指向关键字的节点,所以每一次查询都必须从根节点到叶子结点,长度相同
3. b树在解决io效率的时候并没有解决元素遍历效率低下的问题,而b+树只需要遍历叶子节点就能解决对所有关键字的查询,对于数据库中经常使用的范围查询性能更高
{% asset_img b+树的文件查找结构.jpg b+树的文件查找结构}

### 红黑树

### 创建索引的原则
1. 最左前缀匹配原则
2. =和in可以乱序,mysql会自动优化
3. 尽量选择区分度高的列来做索引
4. 索引列不能参与计算
5. 尽量扩展索引而不是新建
